{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Download CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "def maybe_download_and_extract(\n",
    "  dest_directory='data',\n",
    "  data_url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'):\n",
    "  \n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = dest_directory\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = data_url.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "maybe_download_and_extract(DATA_DIR, DATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Exploring CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_data(index=0, filepath='data/cifar-10-batches-bin/data_batch_5.bin'):\n",
    "  bytestream = open(filepath, mode='rb')\n",
    "\n",
    "  label_bytes_length = 1\n",
    "  image_bytes_length = (32 ** 2) * 3\n",
    "  record_bytes_length = label_bytes_length + image_bytes_length\n",
    "\n",
    "  bytestream.seek(record_bytes_length * index, 0)\n",
    "  label_bytes = bytestream.read(label_bytes_length)\n",
    "  image_bytes = bytestream.read(image_bytes_length)\n",
    "\n",
    "  label = np.frombuffer(label_bytes, dtype=np.uint8)  \n",
    "  image = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  \n",
    "  image = np.reshape(image, [3, 32, 32])\n",
    "  image = np.transpose(image, [1, 2, 0])\n",
    "  image = image.astype(np.float32)\n",
    "  \n",
    "  result = {\n",
    "    'image': image,\n",
    "    'label': label,\n",
    "  }\n",
    "  bytestream.close()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "result = extract_data(np.random.randint(1000))\n",
    "plt.imshow(result['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to use the TF Estimator APIs\n",
    "1. Define dataset **metadata** and **global constants**\n",
    "2. Define **data input function** to read the data from the source + **apply pre-processing**\n",
    "3. Create TF **feature columns** based on metadata + **extended feature columns**\n",
    "4. Instantiate a **model function** with the required **feature columns, EstimatorSpecs, & parameters**\n",
    "5. Define a **serving function**\n",
    "6. Run **Experiment** by supplying training and validation data, as well as required parameters\n",
    "7. **Evaluate** the model using test data\n",
    "8. Perform **predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorflow.python.feature_column import feature_column\n",
    "\n",
    "from tensorflow.contrib.learn import learn_runner\n",
    "from tensorflow.contrib.learn import make_export_strategy\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_files = ['data/cifar-10-batches-bin/data_batch_{}.bin'.format(i) for i in range(1,5)]\n",
    "valid_data_files = ['data/cifar-10-batches-bin/data_batch_5.bin']\n",
    "test_data_files = ['data/cifar-10-batches-bin/test_batch.bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define dataset metadata and global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process images of this size. Note that this differs from the original CIFAR\n",
    "# image size of 32 x 32. If one alters this number, then the entire model\n",
    "# architecture will change and any model would need to be retrained.\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "NUM_CLASSES = 10\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# If a model is trained with multiple GPUs, prefix all Op names with tower_name\n",
    "# to differentiate the operations. Note that this prefix is removed from the\n",
    "# names of the summaries when visualizing a model.\n",
    "TOWER_NAME = 'tower'\n",
    "\n",
    "# We use a weight decay of 0.0002, which performs better than the 0.0001 that\n",
    "# was originally suggested.\n",
    "WEIGHT_DECAY = 2e-4\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "# Global constants describing model behaviors\n",
    "MODEL_NAME = 'cnn-model-02'\n",
    "USE_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Input Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. parsing CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_record(raw_record):\n",
    "  # Every record consists of a label followed by the image, with a fixed number\n",
    "  # of bytes for each.\n",
    "  label_bytes = 1\n",
    "  image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "  record_bytes = label_bytes + image_bytes\n",
    "  \n",
    "  # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  record_vector = tf.decode_raw(raw_record, tf.uint8)\n",
    "  \n",
    "  # The first byte represents the label, which we convert from uint8 to int32\n",
    "  # and then to one-hot.\n",
    "  label = tf.cast(record_vector[0], tf.int32)\n",
    "  label = tf.one_hot(label, NUM_CLASSES)\n",
    "  \n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(\n",
    "    record_vector[label_bytes:record_bytes], [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "  \n",
    "  # Convert from [depth, height, width] to [height, width, depth], and cast as\n",
    "  # float32.\n",
    "  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n",
    "  \n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. preprocessing CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image, is_training=False):\n",
    "  \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "  if is_training:\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image, IMAGE_HEIGHT + 8, IMAGE_WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  image = tf.image.per_image_standardization(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. data pipeline input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_fn(file_names,\n",
    "                      mode=tf.estimator.ModeKeys.EVAL,\n",
    "                      num_epochs=None,\n",
    "                      batch_size=1):\n",
    "\n",
    "  def _input_fn():\n",
    "    label_bytes = 1\n",
    "    image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    dataset = tf.data.FixedLengthRecordDataset(filenames=file_names,\n",
    "                                               record_bytes=record_bytes)\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    if is_training:\n",
    "      buffer_size = batch_size * 2 + 1\n",
    "      dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.map(lambda image, label: (preprocess_image(image, is_training), label))\n",
    "\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "    # Batch results by up to batch_size, and then fetch the tuple from the\n",
    "    # iterator.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "\n",
    "    features = {'images': images}\n",
    "    return features, labels\n",
    "  \n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_columns():\n",
    "  feature_columns = {\n",
    "    'images': tf.feature_column.numeric_column('images', (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)),\n",
    "  }\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = get_feature_columns()\n",
    "print(\"Feature Columns: {}\".format(feature_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  # Define input tensor in Keras world.\n",
    "  model.add(tf.keras.layers.InputLayer(input_shape=(IMAGE_WIDTH*IMAGE_HEIGHT*IMAGE_DEPTH,), name='images'))\n",
    "  model.add(tf.keras.layers.Reshape(target_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_DEPTH)))\n",
    "  # The first convolutional layer.\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "  # The second convolutional layer.\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "  # The third convolutional layer\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    \n",
    "  # The fourth convolutional layer\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "  model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
    "  model.add(tf.keras.layers.Activation('softmax'))\n",
    "  \n",
    "  opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train, Evaluate and Export ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Set HParam and RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 200\n",
    "TRAIN_SIZE = 50000\n",
    "NUM_EVAL = 1\n",
    "CHECKPOINT_STEPS = int((TRAIN_SIZE/BATCH_SIZE) * (NUM_EPOCHS/NUM_EVAL))\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "  num_epochs=NUM_EPOCHS,\n",
    "  batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "model_dir = 'trained_models/{}'.format(MODEL_NAME)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "  save_checkpoints_steps=CHECKPOINT_STEPS,\n",
    "  tf_random_seed=19851211,\n",
    "  model_dir=model_dir\n",
    ")\n",
    "\n",
    "print(hparams)\n",
    "print(\"Model Directory:\", run_config.model_dir)\n",
    "print(\"\")\n",
    "print(\"Dataset Size:\", TRAIN_SIZE)\n",
    "print(\"Batch Size:\", BATCH_SIZE)\n",
    "print(\"Steps per Epoch:\",TRAIN_SIZE/BATCH_SIZE)\n",
    "print(\"Total Steps:\", (TRAIN_SIZE/BATCH_SIZE)*NUM_EPOCHS)\n",
    "print(\"Required Evaluation Steps:\", NUM_EVAL) \n",
    "print(\"That is 1 evaluation step after each\",NUM_EPOCHS/NUM_EVAL,\" epochs\")\n",
    "print(\"Save Checkpoint After\",CHECKPOINT_STEPS,\"steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Define Serving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "\n",
    "  receiver_tensor = {'images': tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32)}\n",
    "  features = {'images': tf.map_fn(preprocess_image, receiver_tensor['images'])}\n",
    "  \n",
    "  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(keras_model=get_model(), model_dir=model_dir)\n",
    "\n",
    "# TF.Keras seems not to support exporter...\n",
    "exporter = None\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "  input_fn=generate_input_fn(file_names=train_data_files,\n",
    "                             mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "                             num_epochs=hparams.num_epochs,\n",
    "                             batch_size=hparams.batch_size),\n",
    "  max_steps=1000,\n",
    "  hooks=None\n",
    ")\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "  input_fn=generate_input_fn(file_names=valid_data_files,\n",
    "                             mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "                             num_epochs=hparams.num_epochs,\n",
    "                             batch_size=hparams.batch_size),\n",
    "  steps=50,\n",
    "  name=None,\n",
    "  hooks=None,\n",
    "  exporters=exporter, # Iterable of Exporters, or single one or None.\n",
    "  start_delay_secs=120,\n",
    "  throttle_secs=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_CHECKPOINT:\n",
    "  print(\"Removing previous artifacts...\")\n",
    "  shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "valid_size = 1000\n",
    "test_size = 1000\n",
    "\n",
    "train_input_fn = generate_input_fn(file_names=train_data_files,\n",
    "                                   mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "                                   num_epochs=None,\n",
    "                                   batch_size=train_size)\n",
    "\n",
    "valid_input_fn = generate_input_fn(file_names=valid_data_files,\n",
    "                                   mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "                                   num_epochs=None,\n",
    "                                   batch_size=valid_size)\n",
    "\n",
    "test_input_fn = generate_input_fn(file_names=test_data_files,\n",
    "                                  mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "                                  num_epochs=None,\n",
    "                                  batch_size=test_size)\n",
    "\n",
    "train_results = estimator.evaluate(input_fn=train_input_fn, steps=1)\n",
    "print()\n",
    "print(\"######################################################################################\")\n",
    "print(\"# {}\".format(train_results))\n",
    "print(\"######################################################################################\")\n",
    "\n",
    "valid_results = estimator.evaluate(input_fn=valid_input_fn, steps=1)\n",
    "print()\n",
    "print(\"######################################################################################\")\n",
    "print(\"# {}\".format(valid_results))\n",
    "print(\"######################################################################################\")\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn, steps=1)\n",
    "print()\n",
    "print(\"######################################################################################\")\n",
    "print(\"# {}\".format(test_results))\n",
    "print(\"######################################################################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_results = estimator.predict(input_fn=test_input_fn)\n",
    "\n",
    "for i in test_results:\n",
    "  print(i)\n",
    "print()\n",
    "print(\"######################################################################################\")\n",
    "print(\"# {}\".format(test_results))\n",
    "print(\"######################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "export_dir = model_dir + '/export/Servo/'\n",
    "saved_model_dir = os.path.join(export_dir, os.listdir(export_dir)[-1]) \n",
    "\n",
    "print(saved_model_dir)\n",
    "print('')\n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "  export_dir = saved_model_dir,\n",
    "  signature_def_key='predictions')\n",
    "\n",
    "N = 1000\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "for i in range(N):\n",
    "  result = extract_data(i)\n",
    "  images.append(result['image'])\n",
    "  labels.append(result['label'][0])\n",
    "\n",
    "output = predictor_fn(\n",
    "  {\n",
    "    'images': images,\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum([a==r for a, r in zip(labels, output['classes'])]) / float(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "    TensorBoard().stop(pid)\n",
    "    print 'Stopped TensorBoard with pid {}'.format(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Using tf.keras for the Inference Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, mode):\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    tf.keras.backend.set_learning_phase(True)\n",
    "  else:\n",
    "    tf.keras.backend.set_learning_phase(False)\n",
    "        \n",
    "  model = tf.keras.models.Sequential()\n",
    "  # Define input tensor in Keras world.\n",
    "  model.add(tf.keras.layers.InputLayer(input_tensor=images))\n",
    "    \n",
    "  # The first convolutional layer.\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "  # The second convolutional layer.\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "  # The third convolutional layer\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    \n",
    "  # The fourth convolutional layer\n",
    "  model.add(tf.keras.layers.Conv2D(\n",
    "      filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.25))\n",
    "    \n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "  model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
    "    \n",
    "  logits = model.output\n",
    "    \n",
    "  return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Using gRPC to get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from grpc.beta import implementations\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2\n",
    "\n",
    "def predict_with_grpc():\n",
    "  \"\"\"                                                                                                                                     \n",
    "  Note that you are running TensorFlow Serving with below commands.                                                                       \n",
    "  tensorflow_model_server --port=9000 --model_name=cnn-model-01 --model_base_path=./cnn-model-01                                          \n",
    "\n",
    "  In addition, make sure cnn-model-01 directory is organized as follows:                                                                  \n",
    "\n",
    "  cnn-model-01/:                                                                                                                          \n",
    "  {random_value}                                                                                                                              \n",
    "\n",
    "  cnn-model-01/{randam_value}/:                                                                                                           \n",
    "  saved_model.pb  variables                                                                                                               \n",
    "  \"\"\"\n",
    "  host = 'localhost'\n",
    "  port = '9000'\n",
    "  channel = implementations.insecure_channel(host, int(port))\n",
    "  stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)\n",
    "\n",
    "  result = extract_data(0)\n",
    "  request = predict_pb2.PredictRequest()\n",
    "  request.model_spec.name = 'cnn-model-01'\n",
    "  request.model_spec.signature_name = 'predictions'\n",
    "  image = result['image']\n",
    "  label = result['label']\n",
    "  request.inputs['images'].CopyFrom(\n",
    "      tf.contrib.util.make_tensor_proto(image, shape=[1, 32, 32, 3]))\n",
    "\n",
    "  result_future = stub.Predict.future(request, 5.0)\n",
    "  print(result_future.result().outputs['classes'].int64_val)\n",
    "  print(result_future.result().outputs['probabilities'].float_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
